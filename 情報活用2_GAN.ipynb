{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/S-HATANO1970/otemae/blob/main/%E6%83%85%E5%A0%B1%E6%B4%BB%E7%94%A82_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ä¸‹è¨˜ã‚³ãƒ¼ãƒ‰ã‚’å…ˆã«å®Ÿè¡Œã™ã‚‹"
      ],
      "metadata": {
        "id": "18RzgVhIUO9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install japanize-matplotlib\n",
        "import japanize_matplotlib"
      ],
      "metadata": {
        "id": "2xLrlvhoPXt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GANãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸç”»åƒç”ŸæˆAIã‚·ã‚¹ãƒ†ãƒ \n",
        "shape_typeã‚’å¤‰æ›´ã™ã‚‹ã¨ç”Ÿæˆã™ã‚‹ç”»åƒãŒå¤‰ãˆã‚‰ã‚Œã¾ã™ã€‚\n",
        "* æ­£æ–¹å½¢:square\n",
        "* é•·æ–¹å½¢:rectangle\n",
        "* å††:circle\n",
        "* ä¸‰è§’å½¢:triangle\n",
        "* ç¸¦ç·š:virtical\n",
        "* æ¨ªç·š:horizontal\n",
        "* æ–œã‚ç·š:diagonal"
      ],
      "metadata": {
        "id": "gnEuU6I7UV4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# è¶…ã‚·ãƒ³ãƒ—ãƒ«ãªç”»åƒç”ŸæˆAIå­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ \n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from typing import Optional, Any\n",
        "\n",
        "# ========================================\n",
        "# 1. å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ\n",
        "# ========================================\n",
        "\n",
        "def create_simple_shapes(num_samples:int=1000, img_size:int=28) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    ã‚·ãƒ³ãƒ—ãƒ«ãªç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ\n",
        "    \"\"\"\n",
        "    images = []\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        # 28x28ã®é»’ã„ç”»åƒã‚’ä½œæˆ\n",
        "        img = np.zeros((img_size, img_size))\n",
        "\n",
        "        # å›³å½¢ã‚’é¸æŠ\n",
        "        shape_type = 'vertical'\n",
        "        # shape_type = np.random.choice(['square','circle','triangle'])\n",
        "        # shape_type = np.random.choice(['horizontal','vertical','diagonal'])\n",
        "\n",
        "        # å›³å½¢ã®ã‚µã‚¤ã‚ºã¨ä½ç½®ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«æ±ºå®š\n",
        "        size = np.random.randint(10, 12)  # ã‚µã‚¤ã‚ºã‚’å°ã•ã‚ã«èª¿æ•´\n",
        "        margin = size // 2 + 1  # å¢ƒç•Œã‹ã‚‰ã®ä½™ç™½\n",
        "        center_x = np.random.randint(margin, img_size - margin)\n",
        "        center_y = np.random.randint(margin, img_size - margin)\n",
        "        stripe_width = np.random.randint(2, 6)\n",
        "\n",
        "        if shape_type == 'square':\n",
        "            # å››è§’å½¢ã‚’æç”»\n",
        "            img[center_y-size//2:center_y+size//2,\n",
        "                center_x-size//2:center_x+size//2] = 1.0\n",
        "\n",
        "        elif shape_type == 'rectangle':\n",
        "            # å››è§’å½¢ã‚’æç”»\n",
        "            img[center_y-size//2:center_y+size,\n",
        "                center_x-size//2:center_x+size//2] = 1.0\n",
        "\n",
        "        elif shape_type == 'circle':\n",
        "            # å††ã‚’æç”»\n",
        "            y, x = np.ogrid[:img_size, :img_size]\n",
        "            mask = (x - center_x)**2 + (y - center_y)**2 <= (size//2)**2\n",
        "            img[mask] = 1.0\n",
        "\n",
        "        elif shape_type == 'triangle':\n",
        "            # ä¸‰è§’å½¢ã‚’æç”»ï¼ˆç°¡æ˜“ç‰ˆï¼‰\n",
        "            for i in range(size):\n",
        "                start = center_x - i//2\n",
        "                end = center_x + i//2 + 1\n",
        "                y_pos = center_y - size//2 + i\n",
        "                if 0 <= y_pos < img_size:\n",
        "                    img[y_pos, max(0, start):min(img_size, end)] = 1.0\n",
        "\n",
        "        elif shape_type == 'horizontal':\n",
        "            # æ¨ªç¸ãƒ‘ã‚¿ãƒ¼ãƒ³\n",
        "            for y in range(img_size):\n",
        "                if (y // stripe_width) % 2 == 0:\n",
        "                    img[y, :] = 1.0\n",
        "\n",
        "        elif shape_type == 'vertical':\n",
        "            # ç¸¦ç¸ãƒ‘ã‚¿ãƒ¼ãƒ³\n",
        "            for x in range(img_size):\n",
        "                if (x // stripe_width) % 2 == 0:\n",
        "                    img[:, x] = 1.0\n",
        "\n",
        "        elif shape_type == 'diagonal':\n",
        "            # æ–œã‚ç¸ãƒ‘ã‚¿ãƒ¼ãƒ³\n",
        "            for y in range(img_size):\n",
        "                for x in range(img_size):\n",
        "                    if ((x + y) // stripe_width) % 2 == 0:\n",
        "                        img[y, x] = 1.0\n",
        "        images.append(img)\n",
        "\n",
        "    return np.array(images)\n",
        "\n",
        "# ========================================\n",
        "# 2. AIã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹é€ å®šç¾©\n",
        "# ========================================\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    \"\"\"\n",
        "    ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ï¼šãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¤ã‚ºã‹ã‚‰ç”»åƒã‚’ç”Ÿæˆã™ã‚‹AI\n",
        "    \"\"\"\n",
        "    def __init__(self, noise_dim:int=100, img_dim:int=784) -> None:  # 28x28 = 784\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        # ã‚·ãƒ³ãƒ—ãƒ«ãª3å±¤æ§‹é€ \n",
        "        self.net = nn.Sequential(\n",
        "            # ãƒã‚¤ã‚º â†’ 128æ¬¡å…ƒ\n",
        "            nn.Linear(noise_dim, 128),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # 128æ¬¡å…ƒ â†’ 256æ¬¡å…ƒ\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # 256æ¬¡å…ƒ â†’ ç”»åƒã‚µã‚¤ã‚ºï¼ˆ784æ¬¡å…ƒï¼‰\n",
        "            nn.Linear(256, img_dim),\n",
        "            nn.Sigmoid()  # 0-1ã®ç¯„å›²ã«æ­£è¦åŒ–\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.net(x)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    \"\"\"\n",
        "    ãƒ‡ã‚£ã‚¹ã‚¯ãƒªãƒŸãƒãƒ¼ã‚¿ï¼šç”»åƒãŒæœ¬ç‰©ã‹å½ç‰©ã‹ã‚’åˆ¤å®šã™ã‚‹AI\n",
        "    \"\"\"\n",
        "    def __init__(self, img_dim:int=784) -> None:  # 28x28 = 784\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        # ã‚·ãƒ³ãƒ—ãƒ«ãª3å±¤æ§‹é€ \n",
        "        self.net = nn.Sequential(\n",
        "            # ç”»åƒï¼ˆ784æ¬¡å…ƒï¼‰ â†’ 256æ¬¡å…ƒ\n",
        "            nn.Linear(img_dim, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            # 256æ¬¡å…ƒ â†’ 128æ¬¡å…ƒ\n",
        "            nn.Linear(256, 128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            # 128æ¬¡å…ƒ â†’ 1æ¬¡å…ƒï¼ˆæœ¬ç‰©ã‹å½ç‰©ã‹ã®åˆ¤å®šï¼‰\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()  # 0-1ã®ç¢ºç‡å€¤\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.net(x)\n",
        "\n",
        "# ========================================\n",
        "# 3. å­¦ç¿’å¯èƒ½ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š\n",
        "# ========================================\n",
        "\n",
        "class GANTrainer:\n",
        "    def __init__(self):\n",
        "        # ã€å—è¬›è€…ãŒå¤‰æ›´å¯èƒ½ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€‘\n",
        "        self.noise_dim = 1        # ãƒã‚¤ã‚ºã®æ¬¡å…ƒæ•°ï¼ˆå¤§ãã„ã»ã©å¤šæ§˜æ€§â†‘ï¼‰\n",
        "        self.learning_rate = 0.0002 # å­¦ç¿’ç‡ï¼ˆå¤§ãã„ã»ã©å­¦ç¿’é€Ÿåº¦â†‘ã€ä¸å®‰å®šã«ãªã‚Šã‚„ã™ã„ï¼‰\n",
        "        self.batch_size = 64        # ãƒãƒƒãƒã‚µã‚¤ã‚ºï¼ˆå¤§ãã„ã»ã©å®‰å®šã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡â†‘ï¼‰\n",
        "\n",
        "        # AIãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆæœŸåŒ–\n",
        "        self.generator = Generator(self.noise_dim)\n",
        "        self.discriminator = Discriminator()\n",
        "\n",
        "        # æœ€é©åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆAdamï¼‰ã‚’è¨­å®š\n",
        "        self.g_optimizer = optim.Adam(self.generator.parameters(), lr=self.learning_rate)\n",
        "        self.d_optimizer = optim.Adam(self.discriminator.parameters(), lr=self.learning_rate)\n",
        "\n",
        "        # æå¤±é–¢æ•°ï¼ˆäºŒå€¤äº¤å·®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ï¼‰\n",
        "        self.criterion = nn.BCELoss()\n",
        "\n",
        "        # å­¦ç¿’éç¨‹ã‚’è¨˜éŒ²\n",
        "        self.initial_samples: Optional[np.ndarray] = None\n",
        "        self.g_losses = []\n",
        "        self.d_losses = []\n",
        "        self.generated_images = []\n",
        "\n",
        "    def train_step(self, real_images: torch.Tensor) -> tuple:\n",
        "        \"\"\"\n",
        "        1å›ã®å­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—\n",
        "        \"\"\"\n",
        "        batch_size = real_images.size(0)\n",
        "\n",
        "        # ãƒ©ãƒ™ãƒ«ä½œæˆï¼ˆæœ¬ç‰©=1ã€å½ç‰©=0ï¼‰\n",
        "        real_labels = torch.ones(batch_size, 1)\n",
        "        fake_labels = torch.zeros(batch_size, 1)\n",
        "\n",
        "        # ========================================\n",
        "        # ãƒ‡ã‚£ã‚¹ã‚¯ãƒªãƒŸãƒãƒ¼ã‚¿ã®å­¦ç¿’\n",
        "        # ========================================\n",
        "\n",
        "        # æœ¬ç‰©ç”»åƒã§ã®å­¦ç¿’\n",
        "        real_outputs = self.discriminator(real_images)\n",
        "        d_loss_real = self.criterion(real_outputs, real_labels)\n",
        "\n",
        "        # å½ç‰©ç”»åƒã‚’ç”Ÿæˆ\n",
        "        noise = torch.randn(batch_size, self.noise_dim)\n",
        "        fake_images = self.generator(noise)\n",
        "\n",
        "        # å½ç‰©ç”»åƒã§ã®å­¦ç¿’\n",
        "        fake_outputs = self.discriminator(fake_images.detach())\n",
        "        d_loss_fake = self.criterion(fake_outputs, fake_labels)\n",
        "\n",
        "        # ãƒ‡ã‚£ã‚¹ã‚¯ãƒªãƒŸãƒãƒ¼ã‚¿ã®ç·æå¤±\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "\n",
        "        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°\n",
        "        self.d_optimizer.zero_grad()\n",
        "        d_loss.backward()\n",
        "        self.d_optimizer.step()\n",
        "\n",
        "        # ========================================\n",
        "        # ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã®å­¦ç¿’\n",
        "        # ========================================\n",
        "\n",
        "        # æ–°ã—ã„ãƒã‚¤ã‚ºã§å½ç‰©ç”»åƒã‚’ç”Ÿæˆ\n",
        "        noise = torch.randn(batch_size, self.noise_dim)\n",
        "        fake_images = self.generator(noise)\n",
        "\n",
        "        # ãƒ‡ã‚£ã‚¹ã‚¯ãƒªãƒŸãƒãƒ¼ã‚¿ã«å½ç‰©ã‚’ã€Œæœ¬ç‰©ã€ã¨ã—ã¦é¨™ã›ã‚‹ã‹ãƒ†ã‚¹ãƒˆ\n",
        "        fake_outputs = self.discriminator(fake_images)\n",
        "        g_loss = self.criterion(fake_outputs, real_labels)  # æœ¬ç‰©ãƒ©ãƒ™ãƒ«ã§å­¦ç¿’\n",
        "\n",
        "        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°\n",
        "        self.g_optimizer.zero_grad()\n",
        "        g_loss.backward()\n",
        "        self.g_optimizer.step()\n",
        "\n",
        "        return d_loss.item(), g_loss.item()\n",
        "\n",
        "    def generate_sample(self, num_samples:int=16) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã‚’ç”Ÿæˆ\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            noise = torch.randn(num_samples, self.noise_dim)\n",
        "            fake_images = self.generator(noise)\n",
        "            return fake_images.view(-1, 28, 28).numpy()\n",
        "\n",
        "# ========================================\n",
        "# 4. å®Ÿéš›ã®å­¦ç¿’å®Ÿè¡Œã¨å¯è¦–åŒ–\n",
        "# ========================================\n",
        "\n",
        "def run_learning_experiment() -> GANTrainer:\n",
        "    \"\"\"\n",
        "    å­¦ç¿’å®Ÿé¨“ã‚’å®Ÿè¡Œ\n",
        "    \"\"\"\n",
        "    print(\"ğŸ¤– ç”»åƒç”ŸæˆAIå­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹ï¼\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # 1. å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ\n",
        "    print(\"ğŸ“Š å­¦ç¿’ç”¨ã®å›³å½¢ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆä¸­...\")\n",
        "    real_data = create_simple_shapes(num_samples=5000)\n",
        "    real_tensor = torch.FloatTensor(real_data.reshape(-1, 784))\n",
        "\n",
        "    # ãƒ‡ãƒ¼ã‚¿ã®ä¾‹ã‚’è¡¨ç¤º\n",
        "    plt.figure(figsize=(10, 2))\n",
        "    for i in range(5):\n",
        "        plt.subplot(1, 5, i+1)\n",
        "        plt.imshow(real_data[i], cmap='gray')\n",
        "        plt.title(f'å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ {i+1}')\n",
        "        plt.axis('off')\n",
        "    plt.suptitle('å­¦ç¿’ã«ä½¿ç”¨ã™ã‚‹å›³å½¢ãƒ‡ãƒ¼ã‚¿ï¼ˆä¾‹ï¼‰')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 2. GANãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚’åˆæœŸåŒ–\n",
        "    trainer = GANTrainer()\n",
        "\n",
        "    print(f\"ğŸ¯ è¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:\")\n",
        "    print(f\"   ãƒã‚¤ã‚ºæ¬¡å…ƒæ•°: {trainer.noise_dim}\")\n",
        "    print(f\"   å­¦ç¿’ç‡: {trainer.learning_rate}\")\n",
        "    print(f\"   ãƒãƒƒãƒã‚µã‚¤ã‚º: {trainer.batch_size}\")\n",
        "    print()\n",
        "\n",
        "    # 3. å­¦ç¿’å‰ã®ç”Ÿæˆä¾‹ã‚’è¡¨ç¤º\n",
        "    print(\"ğŸ² å­¦ç¿’å‰ã®ç”Ÿæˆç”»åƒï¼ˆãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¤ã‚ºï¼‰:\")\n",
        "    initial_samples = trainer.generate_sample()\n",
        "\n",
        "    trainer.initial_samples = initial_samples  # â† ã“ã“ãŒãƒã‚¤ãƒ³ãƒˆï¼\n",
        "\n",
        "    plt.figure(figsize=(8, 2))\n",
        "    for i in range(1):\n",
        "        plt.subplot(1, 1, i+1)\n",
        "        plt.imshow(initial_samples[i], cmap='gray')\n",
        "        plt.axis('off')\n",
        "    plt.suptitle('å­¦ç¿’å‰ã®ç”Ÿæˆç”»åƒï¼ˆæ„å‘³ã®ãªã„ãƒã‚¤ã‚ºï¼‰')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 4. å­¦ç¿’ãƒ«ãƒ¼ãƒ—\n",
        "    num_epochs = 20  # ã‚¨ãƒãƒƒã‚¯æ•°ï¼ˆå—è¬›è€…ãŒå¤‰æ›´å¯èƒ½ï¼‰\n",
        "\n",
        "    print(f\"ğŸš€ å­¦ç¿’é–‹å§‹ï¼ˆ{num_epochs}ã‚¨ãƒãƒƒã‚¯ï¼‰...\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # ãƒ‡ãƒ¼ã‚¿ã‚’ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã—ã¦ãƒãƒƒãƒã«åˆ†å‰²\n",
        "        indices = torch.randperm(len(real_tensor))\n",
        "\n",
        "        epoch_d_loss = 0\n",
        "        epoch_g_loss = 0\n",
        "        num_batches = 0\n",
        "\n",
        "        for i in range(0, len(real_tensor), trainer.batch_size):\n",
        "            batch_indices = indices[i:i+trainer.batch_size]\n",
        "            real_batch = real_tensor[batch_indices]\n",
        "\n",
        "            # 1å›ã®å­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—\n",
        "            d_loss, g_loss = trainer.train_step(real_batch)\n",
        "\n",
        "            epoch_d_loss += d_loss\n",
        "            epoch_g_loss += g_loss\n",
        "            num_batches += 1\n",
        "\n",
        "        # ã‚¨ãƒãƒƒã‚¯å¹³å‡æå¤±ã‚’è¨˜éŒ²\n",
        "        avg_d_loss = epoch_d_loss / num_batches\n",
        "        avg_g_loss = epoch_g_loss / num_batches\n",
        "\n",
        "        trainer.d_losses.append(avg_d_loss)\n",
        "        trainer.g_losses.append(avg_g_loss)\n",
        "\n",
        "        # 2ã‚¨ãƒãƒƒã‚¯ã”ã¨ã«é€²æ—è¡¨ç¤º\n",
        "        if (epoch + 1) % 2 == 0:\n",
        "            print(f\"ã‚¨ãƒãƒƒã‚¯ {epoch+1:3d}/{num_epochs} | \"\n",
        "                  f\"Dæå¤±: {avg_d_loss:.4f} | \"\n",
        "                  f\"Gæå¤±: {avg_g_loss:.4f}\")\n",
        "\n",
        "            # ç¾åœ¨ã®ç”Ÿæˆç”»åƒã‚’ä¿å­˜\n",
        "            samples = trainer.generate_sample()\n",
        "            trainer.generated_images.append(samples)\n",
        "\n",
        "    print(\"âœ… å­¦ç¿’å®Œäº†ï¼\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # 5. çµæœã®å¯è¦–åŒ–\n",
        "    visualize_results(trainer)\n",
        "\n",
        "    return trainer\n",
        "\n",
        "def visualize_results(trainer: GANTrainer) -> None:\n",
        "    \"\"\"\n",
        "    å­¦ç¿’çµæœã‚’å¯è¦–åŒ–\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "\n",
        "    # --- ã‚°ãƒ©ãƒ•å…¨ä½“ã®åœŸå°ï¼ˆä¸Šä¸‹2æ®µï¼‰ ---\n",
        "    fig = plt.figure(figsize=(14, 6))\n",
        "\n",
        "    # === 1 ä¸Šæ®µï¼šå­¦ç¿’æ›²ç·š ===\n",
        "    ax1 = fig.add_subplot(2, 1, 1)\n",
        "    ax1.plot(trainer.d_losses, label='ãƒ‡ã‚£ã‚¹ã‚¯ãƒªãƒŸãƒãƒ¼ã‚¿æå¤±', color='blue')\n",
        "    ax1.plot(trainer.g_losses, label='ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿æå¤±', color='red')\n",
        "    ax1.set_xlabel('ã‚¨ãƒãƒƒã‚¯')\n",
        "    ax1.set_ylabel('æå¤±')\n",
        "    ax1.set_title('å­¦ç¿’æ›²ç·šï¼ˆæå¤±ã®å¤‰åŒ–ï¼‰')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True)\n",
        "\n",
        "    # === 2 ä¸‹æ®µï¼šãƒã‚¤ã‚ºç”»åƒ + å­¦ç¿’ç”»åƒ ===\n",
        "\n",
        "    # ãƒã‚¤ã‚ºç”»åƒã‚’1æšå–å¾—\n",
        "    init_sample = None\n",
        "    if trainer.initial_samples is not None:\n",
        "        init_sample =  np.squeeze(trainer.initial_samples[0])\n",
        "\n",
        "    # åˆè¨ˆæšæ•° = ãƒã‚¤ã‚º1æš + ã‚¨ãƒãƒƒã‚¯ã”ã¨ã®è¨˜éŒ²æ•°\n",
        "    num_epochs = len(trainer.generated_images)\n",
        "    total_cols = num_epochs + 1\n",
        "\n",
        "    img:Any = []\n",
        "    # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆã‚¨ãƒªã‚¢ã‚’å®šç¾©ï¼ˆä¸‹æ®µï¼‰\n",
        "    for idx in range(total_cols):\n",
        "        ax2 = fig.add_subplot(2, total_cols, total_cols + idx + 1)  # ä¸‹æ®µã®åˆ—idx\n",
        "\n",
        "        if idx == 0:\n",
        "            img = init_sample\n",
        "            ax2.set_title(\"ãƒã‚¤ã‚º\", fontsize=8)\n",
        "        else:\n",
        "            img = trainer.generated_images[idx - 1][0]  # å„ã‚¨ãƒãƒƒã‚¯ã®æœ€åˆã®ç”»åƒ\n",
        "            img = np.squeeze(img)\n",
        "            ax2.set_title(f'{idx * 2} epoch', fontsize=8)\n",
        "\n",
        "        ax2.imshow(img, cmap='gray')\n",
        "        ax2.axis('off')\n",
        "\n",
        "    # --- æœ€çµ‚è¡¨ç¤º ---\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ========================================\n",
        "# 5. ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å®Ÿé¨“æ©Ÿèƒ½\n",
        "# ========================================\n",
        "\n",
        "def parameter_experiment() -> None:\n",
        "    \"\"\"\n",
        "    ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¤‰æ›´ã—ãŸå®Ÿé¨“\n",
        "    å—è¬›è€…ãŒãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å½±éŸ¿ã‚’å­¦ç¿’ã§ãã‚‹\n",
        "    \"\"\"\n",
        "    print(\"ğŸ”¬ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å®Ÿé¨“ãƒ¢ãƒ¼ãƒ‰\")\n",
        "    print(\"=\" * 50)\n",
        "    print(\"ç•°ãªã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã®å­¦ç¿’çµæœã‚’æ¯”è¼ƒã—ã¾ã™\")\n",
        "    print()\n",
        "\n",
        "    # å®Ÿé¨“ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™\n",
        "    real_data = create_simple_shapes(num_samples=1000)  # å°‘ãªã‚ã§é«˜é€Ÿå®Ÿé¨“\n",
        "    real_tensor = torch.FloatTensor(real_data.reshape(-1, 784))\n",
        "\n",
        "    # ç•°ãªã‚‹å­¦ç¿’ç‡ã§ã®å®Ÿé¨“\n",
        "    learning_rates = [0.00001, 0.0002, 0.005]\n",
        "    results = {}\n",
        "\n",
        "    for lr in learning_rates:\n",
        "        print(f\"ğŸ“ˆ å­¦ç¿’ç‡ {lr} ã§ã®å®Ÿé¨“ä¸­...\")\n",
        "\n",
        "        trainer = GANTrainer()\n",
        "        trainer.learning_rate = lr\n",
        "\n",
        "        # æœ€é©åŒ–å™¨ã‚’å†è¨­å®š\n",
        "        trainer.g_optimizer = optim.Adam(trainer.generator.parameters(), lr=lr)\n",
        "        trainer.d_optimizer = optim.Adam(trainer.discriminator.parameters(), lr=lr)\n",
        "\n",
        "        # çŸ­ã„å­¦ç¿’\n",
        "        for epoch in range(20):\n",
        "            indices = torch.randperm(len(real_tensor))\n",
        "\n",
        "            for i in range(0, len(real_tensor), trainer.batch_size):\n",
        "                batch_indices = indices[i:i+trainer.batch_size]\n",
        "                real_batch = real_tensor[batch_indices]\n",
        "                d_loss, g_loss = trainer.train_step(real_batch)\n",
        "\n",
        "        # çµæœã‚’ä¿å­˜\n",
        "        results[lr] = trainer.generate_sample(num_samples=4)\n",
        "\n",
        "    # çµæœã‚’æ¯”è¼ƒè¡¨ç¤º\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    for i, (lr, samples) in enumerate(results.items()):\n",
        "        for j in range(4):\n",
        "            plt.subplot(3, 4, i*4 + j + 1)\n",
        "            plt.imshow(samples[j], cmap='gray')\n",
        "            # plt.axis('off')\n",
        "\n",
        "            if j == 0:\n",
        "                plt.ylabel(f'å­¦ç¿’ç‡: {lr}', rotation=0, labelpad=50, va='center')\n",
        "\n",
        "    plt.suptitle('å­¦ç¿’ç‡ã«ã‚ˆã‚‹ç”Ÿæˆç”»åƒã®é•ã„', fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"ğŸ’¡ è¦³å¯Ÿãƒã‚¤ãƒ³ãƒˆ:\")\n",
        "    print(\"   - å­¦ç¿’ç‡ãŒé«˜ã„ â†’ å­¦ç¿’ã¯é€Ÿã„ãŒä¸å®‰å®šã«ãªã‚Šã‚„ã™ã„\")\n",
        "    print(\"   - å­¦ç¿’ç‡ãŒä½ã„ â†’ å®‰å®šã ãŒå­¦ç¿’ãŒé…ã„\")\n",
        "    print(\"   - é©åˆ‡ãªãƒãƒ©ãƒ³ã‚¹ãŒé‡è¦ï¼\")\n",
        "\n",
        "# ========================================\n",
        "# 6. ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œéƒ¨åˆ†\n",
        "# ========================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"ğŸ“ ç”»åƒç”ŸæˆAIå­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ \")\n",
        "    print(\"å—è¬›è€…å‘ã‘ï¼šè¶…ã‚·ãƒ³ãƒ—ãƒ«ç‰ˆ\")\n",
        "    print(\"=\" * 50)\n",
        "    print()\n",
        "\n",
        "    # åŸºæœ¬å­¦ç¿’å®Ÿé¨“\n",
        "    trainer = run_learning_experiment()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    # input(\"ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å®Ÿé¨“ã‚’é–‹å§‹ã™ã‚‹ã«ã¯Enterã‚­ãƒ¼ã‚’æŠ¼ã—ã¦ãã ã•ã„...\")\n",
        "\n",
        "    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å®Ÿé¨“\n",
        "    parameter_experiment()\n",
        "\n",
        "    print(\"\\nğŸ‰ ã™ã¹ã¦ã®å®Ÿé¨“ãŒå®Œäº†ã—ã¾ã—ãŸï¼\")\n",
        "    print(\"\\nğŸ’¡ å­¦ç¿’ã®ãƒã‚¤ãƒ³ãƒˆ:\")\n",
        "    print(\"   1. ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã¨ãƒ‡ã‚£ã‚¹ã‚¯ãƒªãƒŸãƒãƒ¼ã‚¿ãŒç«¶äº‰ã—ãªãŒã‚‰å­¦ç¿’\")\n",
        "    print(\"   2. ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã§çµæœãŒå¤§ããå¤‰ã‚ã‚‹\")\n",
        "    print(\"   3. å­¦ç¿’ã®å®‰å®šæ€§ã¨å“è³ªã®ãƒãƒ©ãƒ³ã‚¹ãŒé‡è¦\")\n",
        "    print(\"   4. å®Ÿéš›ã®AIé–‹ç™ºã§ã‚‚åŒæ§˜ã®åŸç†ãŒä½¿ã‚ã‚Œã¦ã„ã‚‹\")"
      ],
      "metadata": {
        "id": "CwBRUbs4PSHF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
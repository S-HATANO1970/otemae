{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "画像認識.ipynb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/S-HATANO1970/otemae/blob/main/%E7%94%BB%E5%83%8F%E8%AA%8D%E8%AD%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 必要なライブラリをインストール（Google Colabでは初回実行時に必要）\n",
        "# !pip install transformers torch Pillow requests\n",
        "\n",
        "# ライブラリをインポート\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import torch\n",
        "\n",
        "# 1. CLIPモデルとプロセッサの読み込み\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "\n",
        "# 2. 画像をURLから読み込む\n",
        "image_url =\"https://kyoto-edu.sakura.ne.jp/althusser/img/fox.jpg\"  # ここに有効な画像URLを指定\n",
        "try:\n",
        "    response = requests.get(image_url)\n",
        "    response.raise_for_status()  # URLが無効な場合にエラーを発生\n",
        "    image = Image.open(BytesIO(response.content))\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error fetching image from URL: {e}\")\n",
        "    exit()\n",
        "except Exception as e:\n",
        "    print(f\"Error processing image: {e}\")\n",
        "    exit()\n",
        "\n",
        "# 3. キャプション候補を定義\n",
        "candidate_captions = [\n",
        "    \"A shark stuffed animal\",\n",
        "    \"A Fox stuffed animal\",\n",
        "    \"A Triceratops stuffed animal\",\n",
        "    \"A person reading a book\",\n",
        "    \"A cup of coffee on a table\"\n",
        "]\n",
        "\n",
        "# 4. 画像とキャプションを処理\n",
        "inputs = processor(text=candidate_captions, images=image, return_tensors=\"pt\", padding=True)\n",
        "\n",
        "# 5. モデルで画像とキャプションのマッチングスコアを計算\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    logits_per_image = outputs.logits_per_image\n",
        "    probs = logits_per_image.softmax(dim=1)\n",
        "\n",
        "# 6. 結果を表示\n",
        "print(\"キャプションと確率:\")\n",
        "for caption, prob in zip(candidate_captions, probs[0]):\n",
        "    print(f\"{caption}: {prob:.4f}\")\n",
        "\n",
        "# 7. 最も確率の高いキャプションを選択\n",
        "best_caption_idx = probs.argmax().item()\n",
        "best_caption = candidate_captions[best_caption_idx]\n",
        "print(f\"\\n最も適切なキャプション: {best_caption} (確率: {probs[0][best_caption_idx]:.4f})\")\n",
        "\n",
        "# 8. 画像を表示（確認用、Google Colabでは表示可能）\n",
        "image.show()"
      ],
      "metadata": {
        "id": "t09YfdgmIa6H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}